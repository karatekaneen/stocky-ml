{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "### Operations\n",
    "- Figure out the least amount of data that needs to be provided\n",
    "- Save + load model and compare results\n",
    "- Build API around it\n",
    "\n",
    "### Features\n",
    "- ~~Add feature for days since last signal~~\n",
    "- ~~Add feature for number of signals last year~~\n",
    "- ~~Kaufmanns efficiency ratio~~\n",
    "- Insider buys/sells\n",
    "- VIX\n",
    "- Interest rates\n",
    "- Squeeze DIX/GEX\n",
    "- Add feature based on output on news model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:\\dev\\stocky-ml\\credentials.json\"\n",
    "\n",
    "# Data:\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dateutil.parser\n",
    "import dateutil.tz as tz\n",
    "from datetime import datetime, timedelta\n",
    "import talib   \n",
    "from talib import MA_Type\n",
    "\n",
    "\n",
    "# Visualization:\n",
    "import seaborn as sns\n",
    "\n",
    "# Database:\n",
    "from google.cloud import firestore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create db instance: \n",
    "db = firestore.Client()\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_data(id):\n",
    "    doc = db.collection('prices').document(id).get().to_dict()\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(doc['priceData'])\n",
    "    df = add_calculated_columns(df)\n",
    "    df = convert_dates(df)\n",
    "\n",
    "    # Read the file to lazily make sure that the dates are strings etc.\n",
    "    # FIXME: Should probably be done some other way.\n",
    "    # output.drop(columns=['Unnamed: 0'], inplace = True)\n",
    "    return df\n",
    "\n",
    "def get_trade_data(doc):\n",
    "    doc = doc.to_dict()\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(doc['trades'])\n",
    "    df['result'] = (df['exitPrice'] / df['entryPrice']) -1\n",
    "    df['trades_last_year'] =  count_trades_last_year(df, df['entryDate'])\n",
    "    shifted = df['exitDate'].shift()\n",
    "    df['days_since_last_signal'] = (df['entryDate'] - shifted).dt.days\n",
    "    # df['days_since_last_signal'] =df['days_since_last_signal'].days\n",
    "\n",
    "    df = convert_trade_dates(df)\n",
    "\n",
    "    return df[['date', 'result', 'trades_last_year',  'days_since_last_signal']]\n",
    "\n",
    "def convert_date(date, fmt = \"%Y-%m-%d\", target_tz = tz.gettz('CET')):\n",
    "    return date.replace(tzinfo=tz.gettz(\"UTC\")).astimezone(target_tz).strftime(fmt)\n",
    "\n",
    "def count_trades_last_year(df, d):\n",
    "    # print(d)\n",
    "    out = []\n",
    "\n",
    "    for x in d:\n",
    "        trades_last_year = df[(df['entryDate'] < x - timedelta(days=2)) & (df['entryDate'] >= x - timedelta(days=365))]\n",
    "        out.append(len(trades_last_year))\n",
    "    return out\n",
    "\n",
    "    \n",
    "def convert_dates(df):\n",
    "    cet = tz.gettz('CET')\n",
    "    for i, row in df.iterrows():\n",
    "        d = convert_date(dateutil.parser.isoparse(row['date']))\n",
    "        df.at[i,'date'] = d\n",
    "    return df\n",
    "\n",
    "def kaufmanns_efficiency_ratio(prices, n):\n",
    "    \"\"\"\n",
    "    Calculates Kaufmann's Efficiency Ratio over a lookback of n.\n",
    "    :param prices: list of prices\n",
    "    :param n: lookback period\n",
    "    :return: Kaufmann's Efficiency Ratio\n",
    "    \"\"\"\n",
    "    change = abs(prices[len(prices) -1] - prices[0])\n",
    "    volatility = sum(abs(prices[i] - prices[i-1]) for i in range(1, n))\n",
    "    return change / volatility if volatility != 0 else 0\n",
    "\n",
    "\n",
    "def convert_trade_dates(df):\n",
    "    cet = tz.gettz('CET')\n",
    "    for i, row in df.iterrows():\n",
    "        d = convert_date(row['entryDate'] - timedelta(days=1)) # Want one day earlier so that we don't have look ahead\n",
    "        df.at[i,'date'] = d\n",
    "    return df\n",
    "\n",
    "def add_calculated_columns(price):\n",
    "    lookbacks = [20, 50, 100, 200]\n",
    "    values = ['close', 'volume']\n",
    "        \n",
    "    price['volume_cash'] = round(price['volume'] * (price['close'] * 2 + price['open'] * 2 + price['low'] + price['high'])/6)\n",
    "    for value in values:\n",
    "        for lookback in lookbacks:\n",
    "            # Get the rolling average and std:\n",
    "            price['average'] = price[value].rolling(lookback).mean()\n",
    "            price['std'] = price[value].rolling(lookback).std()\n",
    "            high = price['high'].rolling(lookback).max()\n",
    "            low = price['low'].rolling(lookback).min()\n",
    "            \n",
    "\n",
    "            # Normalize distance to mean. This could be done with the data above but dont know how.\n",
    "            price[f'zs-{lookback}-{value}'] = (price[value] - price['average']) / price['std']\n",
    "\n",
    "            # Get slope of rolling average and std\n",
    "            price[f'ma-slope-{lookback}-{value}'] = price['average'] / price['average'].shift(1)\n",
    "            price[f'std-slope-{lookback}-{value}'] = price['std'] / price['std'].shift(1)\n",
    "\n",
    "            # Get range\n",
    "            price[f'rng-{lookback}'] = high / low\n",
    "            price[f'percent-rng-{lookback}-{value}'] = (high / low) / price[value]\n",
    "            price[f'percent-std-{lookback}-{value}'] = price['std'] / price[value]\n",
    "\n",
    "            if value == 'volume':\n",
    "                price['temp_volume'] = round(price['volume'] * (price['close'] * 2 + price['open'] * 2 + price['low'] + price['high'])/6)\n",
    "                # price[f'avg-log-volume-{lookback}'] = np.log10(price['temp_volume'])  \n",
    "                price.drop(columns=['temp_volume'], inplace = True)\n",
    "            else:\n",
    "                # Hehe, so bad code\n",
    "                # apply the kaufmanns_efficiency_ratio function to a rolling window of the close column\n",
    "                price[f'kaufmanns_efficiency_ratio-{lookback}'] = price['close'].rolling(window=lookback).apply(lambda x: kaufmanns_efficiency_ratio(x.tolist(), lookback))\n",
    "\n",
    "\n",
    "            # Drop the actual values since they carry no interest:\n",
    "            price.drop(columns=['average', 'std'], inplace = True)\n",
    "            \n",
    "        # TODO: Add calculations for volume\n",
    "        # TODO: Add calculations for owners\n",
    "    return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_index_stock_df(omxdf, stockdf):\n",
    "  df = pd.merge(stockdf[['date', 'close']], omxdf[['date', 'close']], on='date', suffixes=('_stock', '_omx'))\n",
    "  # df['date'] = df['date_stock']\n",
    "  df['stock_quota'] = df['close_stock']/df['close_omx']\n",
    "\n",
    "\n",
    "  df['stock_hist_relative_perf20'] = df['stock_quota'].shift(20) / df['stock_quota']\n",
    "  df['stock_hist_relative_perf50'] = df['stock_quota'].shift(50) / df['stock_quota']\n",
    "  df['stock_hist_relative_perf100'] = df['stock_quota'].shift(100) / df['stock_quota']\n",
    "\n",
    "  df['stock_hist_perf20'] = df['close_stock'].shift(20) / df['close_stock']\n",
    "  df['stock_hist_perf50'] = df['close_stock'].shift(50) / df['close_stock']\n",
    "  df['stock_hist_perf100'] = df['close_stock'].shift(100) / df['close_stock']\n",
    "\n",
    "  for p in [3, 10, 34, 100]:\n",
    "    df[f'stock_relative_rsi_{p}'] = talib.RSI(df['stock_quota'], timeperiod=p) /100\n",
    "    df[f'stock_rsi_{p}'] = talib.RSI(df['close_stock'], timeperiod=p) / 100\n",
    "\n",
    "  df.drop(columns=['close_stock', 'close_omx'], inplace = True)\n",
    "\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the omx price data\n",
    "omxdf = get_price_data('19002')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwanted_columns = [\n",
    "                'Unnamed: 0',\n",
    "                # These values does not carry much importance\n",
    "                'volume_omx',\n",
    "                'owners_omx',\n",
    "                'date',\n",
    "                'high_stock',\n",
    "                'low_stock',\n",
    "                'owners_stock',\n",
    "                # 'close_stock',\n",
    "                'open_stock',\n",
    "                'high_omx',\n",
    "                'low_omx',\n",
    "                'owners_omx',\n",
    "                'close_omx',\n",
    "                'open_omx',\n",
    "                # Theses values are missing a lot of the time and would result in a lot of rows being dropped.\n",
    "                # TODO: See if you can improve the data quality to be able to use more of these\n",
    "                'owners_stock', \n",
    "                'zs-20-volume_omx',\n",
    "                'ma-slope-20-volume_omx',\n",
    "                'std-slope-20-volume_omx',\n",
    "                'percent-rng-20-volume_omx',\n",
    "                'percent-std-20-volume_omx',\n",
    "                'avg-log-volume-20_omx',\n",
    "                'zs-50-volume_omx',\n",
    "                'ma-slope-50-volume_omx',\n",
    "                'std-slope-50-volume_omx',\n",
    "                'percent-rng-50-volume_omx',\n",
    "                'percent-std-50-volume_omx',\n",
    "                'avg-log-volume-50_omx',\n",
    "                'zs-100-volume_omx',\n",
    "                'ma-slope-100-volume_omx',\n",
    "                'std-slope-100-volume_omx',\n",
    "                'percent-rng-100-volume_omx',\n",
    "                'percent-std-100-volume_omx',\n",
    "                'avg-log-volume-100_omx',\n",
    "                'zs-200-volume_omx',\n",
    "                'ma-slope-200-volume_omx',\n",
    "                'std-slope-200-volume_omx',\n",
    "                'percent-rng-200-volume_omx',\n",
    "                'percent-std-200-volume_omx',\n",
    "                'avg-log-volume-200_omx',\n",
    "                'zs-200-volume_stock',            \n",
    "                'ma-slope-200-volume_stock',      \n",
    "                'std-slope-200-volume_stock',     \n",
    "                'percent-rng-200-volume_stock',  \n",
    "                'percent-std-200-volume_stock',   \n",
    "                'zs-100-volume_stock',            \n",
    "                'ma-slope-100-volume_stock',      \n",
    "                'std-slope-100-volume_stock',     \n",
    "                'percent-rng-100-volume_stock',   \n",
    "                'percent-std-100-volume_stock',\n",
    "                'volume_stock',\n",
    "                'volume_cash_omx'\n",
    "                ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "import json\n",
    "from dateutil import parser\n",
    "import joblib\n",
    "\n",
    "vstockdf = pd.read_json('data/stock.json')\n",
    "vomxdf = pd.read_json('data/omx.json')\n",
    "original = pd.read_csv('stockytrades20230410-2.csv')\n",
    "\n",
    "# load the JSON data from a file\n",
    "with open('data/trades.json', 'r') as f:\n",
    "    v_trade_data = json.load(f)\n",
    "\n",
    "# convert the \"triggerDate\" field to a datetime object\n",
    "for item in v_trade_data:\n",
    "    item[\"triggerDate\"] = parser.parse(item[\"triggerDate\"])\n",
    "\n",
    "\n",
    "stockindex = vstockdf.index[(vstockdf['date'] == '2023-01-01T23:00:00+00:00')].item()\n",
    "omxindex = vomxdf.index[(vomxdf['date'] == '2023-01-01T23:00:00+00:00')].item()\n",
    "# TODO: trades_last_year,days_since_last_signal\n",
    "\n",
    "\n",
    "\n",
    "# This is what will be the input\n",
    "vstockres = vstockdf.loc[(stockindex-200):stockindex]\n",
    "v_omx_res = vomxdf.loc[(omxindex-200):omxindex]\n",
    "\n",
    "# All calculated fields to the input\n",
    "vstockres =  add_calculated_columns(vstockres.copy())\n",
    "v_omx_res =  add_calculated_columns(v_omx_res.copy())\n",
    "\n",
    "# v_merged = merge_index_stock_df(v_omx_res, vstockres) \n",
    "v_merged = pd.merge(v_omx_res, vstockres, on='date', suffixes=('_stock', '_omx'))\n",
    "v_merged = pd.merge(v_merged, merge_index_stock_df(v_omx_res, vstockres), on='date')\n",
    "\n",
    "\n",
    "validation_row = v_merged.drop(columns=unwanted_columns,errors='ignore').iloc[-1:]\n",
    "validation_row['days_since_last_signal'] = 342 # NOTE: This is a hardcoded value to mock input from the API\n",
    "validation_row['trades_last_year'] = 1 # NOTE: This is a hardcoded value to mock input from the API\n",
    "\n",
    "# select the rows based on the condition\n",
    "original_row = original.loc[ (original['date'] == '2023-01-02') & (original['close_stock'] == 13.8)].drop(columns=unwanted_columns, errors='ignore').tail(1).iloc[-1:]\n",
    "\n",
    "\n",
    "# Load saved model\n",
    "model = tf.keras.models.load_model('model/model.h5')\n",
    "\n",
    "# Load saved scaler\n",
    "scaler = joblib.load('model/scaler.pkl')\n",
    "\n",
    "# Scale the validation data with the same scaler used for the training data\n",
    "validation_x = scaler.fit_transform(validation_row.drop(columns=['result', 'label'], errors='ignore', axis=1).values)\n",
    "original_x = scaler.fit_transform(original_row.drop(columns=['result', 'label'], errors='ignore', axis=1).values)\n",
    "\n",
    "# # Run predictions on the validation dataset\n",
    "val_pred = model.predict(validation_x)\n",
    "original_pred = model.predict(original_x)\n",
    "print(val_pred, original_pred)\n",
    "\n",
    "# validation_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "have 20449\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_stock</th>\n",
       "      <th>volume_cash_stock</th>\n",
       "      <th>zs-20-close_stock</th>\n",
       "      <th>ma-slope-20-close_stock</th>\n",
       "      <th>std-slope-20-close_stock</th>\n",
       "      <th>rng-20_stock</th>\n",
       "      <th>percent-rng-20-close_stock</th>\n",
       "      <th>percent-std-20-close_stock</th>\n",
       "      <th>kaufmanns_efficiency_ratio-20_stock</th>\n",
       "      <th>zs-50-close_stock</th>\n",
       "      <th>ma-slope-50-close_stock</th>\n",
       "      <th>std-slope-50-close_stock</th>\n",
       "      <th>rng-50_stock</th>\n",
       "      <th>percent-rng-50-close_stock</th>\n",
       "      <th>percent-std-50-close_stock</th>\n",
       "      <th>kaufmanns_efficiency_ratio-50_stock</th>\n",
       "      <th>zs-100-close_stock</th>\n",
       "      <th>ma-slope-100-close_stock</th>\n",
       "      <th>std-slope-100-close_stock</th>\n",
       "      <th>rng-100_stock</th>\n",
       "      <th>percent-rng-100-close_stock</th>\n",
       "      <th>percent-std-100-close_stock</th>\n",
       "      <th>kaufmanns_efficiency_ratio-100_stock</th>\n",
       "      <th>zs-200-close_stock</th>\n",
       "      <th>ma-slope-200-close_stock</th>\n",
       "      <th>...</th>\n",
       "      <th>zs-200-close_omx</th>\n",
       "      <th>ma-slope-200-close_omx</th>\n",
       "      <th>std-slope-200-close_omx</th>\n",
       "      <th>rng-200_omx</th>\n",
       "      <th>percent-rng-200-close_omx</th>\n",
       "      <th>percent-std-200-close_omx</th>\n",
       "      <th>kaufmanns_efficiency_ratio-200_omx</th>\n",
       "      <th>stock_quota</th>\n",
       "      <th>stock_hist_relative_perf20</th>\n",
       "      <th>stock_hist_relative_perf50</th>\n",
       "      <th>stock_hist_relative_perf100</th>\n",
       "      <th>stock_hist_perf20</th>\n",
       "      <th>stock_hist_perf50</th>\n",
       "      <th>stock_hist_perf100</th>\n",
       "      <th>stock_relative_rsi_3</th>\n",
       "      <th>stock_rsi_3</th>\n",
       "      <th>stock_relative_rsi_10</th>\n",
       "      <th>stock_rsi_10</th>\n",
       "      <th>stock_relative_rsi_34</th>\n",
       "      <th>stock_rsi_34</th>\n",
       "      <th>stock_relative_rsi_100</th>\n",
       "      <th>stock_rsi_100</th>\n",
       "      <th>result</th>\n",
       "      <th>trades_last_year</th>\n",
       "      <th>days_since_last_signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15988</th>\n",
       "      <td>2.03</td>\n",
       "      <td>541421.0</td>\n",
       "      <td>2.744165</td>\n",
       "      <td>1.005824</td>\n",
       "      <td>1.307024</td>\n",
       "      <td>1.413317</td>\n",
       "      <td>0.696215</td>\n",
       "      <td>0.038864</td>\n",
       "      <td>0.203209</td>\n",
       "      <td>-0.155546</td>\n",
       "      <td>0.992061</td>\n",
       "      <td>0.957831</td>\n",
       "      <td>1.840452</td>\n",
       "      <td>0.906627</td>\n",
       "      <td>0.179947</td>\n",
       "      <td>0.296882</td>\n",
       "      <td>-0.526132</td>\n",
       "      <td>0.998846</td>\n",
       "      <td>1.001157</td>\n",
       "      <td>1.840452</td>\n",
       "      <td>0.906627</td>\n",
       "      <td>0.165639</td>\n",
       "      <td>0.047735</td>\n",
       "      <td>-0.985840</td>\n",
       "      <td>0.996976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.944756</td>\n",
       "      <td>1.000610</td>\n",
       "      <td>0.999884</td>\n",
       "      <td>1.288141</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.059796</td>\n",
       "      <td>0.066938</td>\n",
       "      <td>0.000933</td>\n",
       "      <td>0.867213</td>\n",
       "      <td>1.392532</td>\n",
       "      <td>1.161365</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>1.411330</td>\n",
       "      <td>1.125616</td>\n",
       "      <td>0.904683</td>\n",
       "      <td>0.943007</td>\n",
       "      <td>0.662436</td>\n",
       "      <td>0.701801</td>\n",
       "      <td>0.483980</td>\n",
       "      <td>0.484571</td>\n",
       "      <td>0.453806</td>\n",
       "      <td>0.455930</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>1</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2535</th>\n",
       "      <td>2.48</td>\n",
       "      <td>53280.0</td>\n",
       "      <td>1.066610</td>\n",
       "      <td>0.996130</td>\n",
       "      <td>0.912574</td>\n",
       "      <td>1.473146</td>\n",
       "      <td>0.594010</td>\n",
       "      <td>0.061810</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>-0.440949</td>\n",
       "      <td>0.998536</td>\n",
       "      <td>1.001130</td>\n",
       "      <td>1.769821</td>\n",
       "      <td>0.713637</td>\n",
       "      <td>0.102235</td>\n",
       "      <td>0.084112</td>\n",
       "      <td>-0.761097</td>\n",
       "      <td>0.998364</td>\n",
       "      <td>0.999189</td>\n",
       "      <td>1.769821</td>\n",
       "      <td>0.713637</td>\n",
       "      <td>0.108396</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.944756</td>\n",
       "      <td>1.000610</td>\n",
       "      <td>0.999884</td>\n",
       "      <td>1.288141</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.059796</td>\n",
       "      <td>0.066938</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>1.031363</td>\n",
       "      <td>1.058178</td>\n",
       "      <td>1.296622</td>\n",
       "      <td>1.072581</td>\n",
       "      <td>1.076613</td>\n",
       "      <td>1.177419</td>\n",
       "      <td>0.836680</td>\n",
       "      <td>0.826858</td>\n",
       "      <td>0.581117</td>\n",
       "      <td>0.576352</td>\n",
       "      <td>0.478057</td>\n",
       "      <td>0.480907</td>\n",
       "      <td>0.456886</td>\n",
       "      <td>0.469512</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>1</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15008</th>\n",
       "      <td>3.29</td>\n",
       "      <td>1262759.0</td>\n",
       "      <td>0.880819</td>\n",
       "      <td>0.994219</td>\n",
       "      <td>0.882303</td>\n",
       "      <td>1.413284</td>\n",
       "      <td>0.429570</td>\n",
       "      <td>0.067031</td>\n",
       "      <td>0.165899</td>\n",
       "      <td>-0.607770</td>\n",
       "      <td>0.998938</td>\n",
       "      <td>1.003415</td>\n",
       "      <td>1.723247</td>\n",
       "      <td>0.523783</td>\n",
       "      <td>0.141381</td>\n",
       "      <td>0.064272</td>\n",
       "      <td>-0.129539</td>\n",
       "      <td>1.003407</td>\n",
       "      <td>0.974340</td>\n",
       "      <td>2.186047</td>\n",
       "      <td>0.664452</td>\n",
       "      <td>0.158734</td>\n",
       "      <td>0.054269</td>\n",
       "      <td>0.727544</td>\n",
       "      <td>1.001494</td>\n",
       "      <td>...</td>\n",
       "      <td>0.944756</td>\n",
       "      <td>1.000610</td>\n",
       "      <td>0.999884</td>\n",
       "      <td>1.288141</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.059796</td>\n",
       "      <td>0.066938</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>1.073118</td>\n",
       "      <td>1.043662</td>\n",
       "      <td>0.674251</td>\n",
       "      <td>1.109422</td>\n",
       "      <td>1.057751</td>\n",
       "      <td>0.653495</td>\n",
       "      <td>0.811952</td>\n",
       "      <td>0.827162</td>\n",
       "      <td>0.564281</td>\n",
       "      <td>0.567580</td>\n",
       "      <td>0.496007</td>\n",
       "      <td>0.495642</td>\n",
       "      <td>0.498714</td>\n",
       "      <td>0.500740</td>\n",
       "      <td>-0.124620</td>\n",
       "      <td>4</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18774</th>\n",
       "      <td>3.95</td>\n",
       "      <td>89900.0</td>\n",
       "      <td>2.406587</td>\n",
       "      <td>1.002250</td>\n",
       "      <td>1.092150</td>\n",
       "      <td>1.416252</td>\n",
       "      <td>0.358545</td>\n",
       "      <td>0.052414</td>\n",
       "      <td>0.167883</td>\n",
       "      <td>0.856915</td>\n",
       "      <td>0.997569</td>\n",
       "      <td>0.954666</td>\n",
       "      <td>1.542289</td>\n",
       "      <td>0.390453</td>\n",
       "      <td>0.076075</td>\n",
       "      <td>0.070619</td>\n",
       "      <td>-0.432947</td>\n",
       "      <td>0.998001</td>\n",
       "      <td>0.995381</td>\n",
       "      <td>1.704809</td>\n",
       "      <td>0.431597</td>\n",
       "      <td>0.142123</td>\n",
       "      <td>0.083643</td>\n",
       "      <td>-0.814556</td>\n",
       "      <td>0.998177</td>\n",
       "      <td>...</td>\n",
       "      <td>0.944756</td>\n",
       "      <td>1.000610</td>\n",
       "      <td>0.999884</td>\n",
       "      <td>1.288141</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.059796</td>\n",
       "      <td>0.066938</td>\n",
       "      <td>0.001816</td>\n",
       "      <td>0.929320</td>\n",
       "      <td>1.099087</td>\n",
       "      <td>1.251172</td>\n",
       "      <td>0.960759</td>\n",
       "      <td>1.113924</td>\n",
       "      <td>1.212658</td>\n",
       "      <td>0.913877</td>\n",
       "      <td>0.957879</td>\n",
       "      <td>0.671920</td>\n",
       "      <td>0.698092</td>\n",
       "      <td>0.513029</td>\n",
       "      <td>0.516961</td>\n",
       "      <td>0.480894</td>\n",
       "      <td>0.485299</td>\n",
       "      <td>-0.035443</td>\n",
       "      <td>1</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2.37</td>\n",
       "      <td>209576.0</td>\n",
       "      <td>3.032243</td>\n",
       "      <td>1.007771</td>\n",
       "      <td>1.412257</td>\n",
       "      <td>1.414286</td>\n",
       "      <td>0.596745</td>\n",
       "      <td>0.048265</td>\n",
       "      <td>0.228095</td>\n",
       "      <td>-0.137957</td>\n",
       "      <td>0.994912</td>\n",
       "      <td>0.985365</td>\n",
       "      <td>1.801143</td>\n",
       "      <td>0.759976</td>\n",
       "      <td>0.191278</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-0.814632</td>\n",
       "      <td>0.994949</td>\n",
       "      <td>0.987717</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>0.964436</td>\n",
       "      <td>0.231530</td>\n",
       "      <td>0.199216</td>\n",
       "      <td>-1.100148</td>\n",
       "      <td>0.997949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.944756</td>\n",
       "      <td>1.000610</td>\n",
       "      <td>0.999884</td>\n",
       "      <td>1.288141</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.059796</td>\n",
       "      <td>0.066938</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>0.839939</td>\n",
       "      <td>1.245632</td>\n",
       "      <td>1.654299</td>\n",
       "      <td>0.868354</td>\n",
       "      <td>1.262447</td>\n",
       "      <td>1.603376</td>\n",
       "      <td>0.922219</td>\n",
       "      <td>0.949521</td>\n",
       "      <td>0.672756</td>\n",
       "      <td>0.685980</td>\n",
       "      <td>0.467637</td>\n",
       "      <td>0.470723</td>\n",
       "      <td>0.424234</td>\n",
       "      <td>0.429815</td>\n",
       "      <td>-0.004158</td>\n",
       "      <td>0</td>\n",
       "      <td>590.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14056</th>\n",
       "      <td>15.00</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>1.779090</td>\n",
       "      <td>1.003655</td>\n",
       "      <td>1.093842</td>\n",
       "      <td>1.171875</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.047590</td>\n",
       "      <td>0.036496</td>\n",
       "      <td>1.215632</td>\n",
       "      <td>1.007848</td>\n",
       "      <td>0.990677</td>\n",
       "      <td>2.094241</td>\n",
       "      <td>0.139616</td>\n",
       "      <td>0.118347</td>\n",
       "      <td>0.073840</td>\n",
       "      <td>1.391710</td>\n",
       "      <td>1.001604</td>\n",
       "      <td>1.009579</td>\n",
       "      <td>2.094241</td>\n",
       "      <td>0.139616</td>\n",
       "      <td>0.120140</td>\n",
       "      <td>0.024740</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.665695</td>\n",
       "      <td>1.001047</td>\n",
       "      <td>1.001067</td>\n",
       "      <td>1.310069</td>\n",
       "      <td>0.001496</td>\n",
       "      <td>0.058674</td>\n",
       "      <td>0.130928</td>\n",
       "      <td>0.017131</td>\n",
       "      <td>0.967337</td>\n",
       "      <td>0.720639</td>\n",
       "      <td>0.971465</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.678072</td>\n",
       "      <td>0.755504</td>\n",
       "      <td>0.555563</td>\n",
       "      <td>0.587648</td>\n",
       "      <td>0.517387</td>\n",
       "      <td>0.530934</td>\n",
       "      <td>0.475994</td>\n",
       "      <td>0.487070</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12033</th>\n",
       "      <td>80.12</td>\n",
       "      <td>128813639.0</td>\n",
       "      <td>1.977155</td>\n",
       "      <td>1.003310</td>\n",
       "      <td>1.105054</td>\n",
       "      <td>1.096980</td>\n",
       "      <td>0.013692</td>\n",
       "      <td>0.021602</td>\n",
       "      <td>0.342804</td>\n",
       "      <td>1.739213</td>\n",
       "      <td>1.002035</td>\n",
       "      <td>1.031118</td>\n",
       "      <td>1.217163</td>\n",
       "      <td>0.015192</td>\n",
       "      <td>0.042803</td>\n",
       "      <td>0.245393</td>\n",
       "      <td>2.342737</td>\n",
       "      <td>1.001654</td>\n",
       "      <td>1.019918</td>\n",
       "      <td>1.237811</td>\n",
       "      <td>0.015449</td>\n",
       "      <td>0.040571</td>\n",
       "      <td>0.115607</td>\n",
       "      <td>1.600892</td>\n",
       "      <td>0.999701</td>\n",
       "      <td>...</td>\n",
       "      <td>1.665695</td>\n",
       "      <td>1.001047</td>\n",
       "      <td>1.001067</td>\n",
       "      <td>1.310069</td>\n",
       "      <td>0.001496</td>\n",
       "      <td>0.058674</td>\n",
       "      <td>0.130928</td>\n",
       "      <td>0.091500</td>\n",
       "      <td>0.969966</td>\n",
       "      <td>0.950477</td>\n",
       "      <td>0.937717</td>\n",
       "      <td>0.936845</td>\n",
       "      <td>0.906016</td>\n",
       "      <td>0.850599</td>\n",
       "      <td>0.668307</td>\n",
       "      <td>0.902318</td>\n",
       "      <td>0.581661</td>\n",
       "      <td>0.690710</td>\n",
       "      <td>0.548916</td>\n",
       "      <td>0.599993</td>\n",
       "      <td>0.479608</td>\n",
       "      <td>0.519502</td>\n",
       "      <td>1.311408</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13017</th>\n",
       "      <td>3.18</td>\n",
       "      <td>2829488.0</td>\n",
       "      <td>2.042188</td>\n",
       "      <td>1.004523</td>\n",
       "      <td>1.136263</td>\n",
       "      <td>1.417355</td>\n",
       "      <td>0.445709</td>\n",
       "      <td>0.045040</td>\n",
       "      <td>0.202614</td>\n",
       "      <td>0.819079</td>\n",
       "      <td>1.006476</td>\n",
       "      <td>0.917558</td>\n",
       "      <td>1.590090</td>\n",
       "      <td>0.500028</td>\n",
       "      <td>0.075249</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>1.400569</td>\n",
       "      <td>1.001511</td>\n",
       "      <td>1.010005</td>\n",
       "      <td>1.626728</td>\n",
       "      <td>0.511550</td>\n",
       "      <td>0.103844</td>\n",
       "      <td>0.039501</td>\n",
       "      <td>0.360249</td>\n",
       "      <td>0.999087</td>\n",
       "      <td>...</td>\n",
       "      <td>1.665695</td>\n",
       "      <td>1.001047</td>\n",
       "      <td>1.001067</td>\n",
       "      <td>1.310069</td>\n",
       "      <td>0.001496</td>\n",
       "      <td>0.058674</td>\n",
       "      <td>0.130928</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>0.950702</td>\n",
       "      <td>0.732372</td>\n",
       "      <td>0.967483</td>\n",
       "      <td>0.918239</td>\n",
       "      <td>0.698113</td>\n",
       "      <td>0.871069</td>\n",
       "      <td>0.726121</td>\n",
       "      <td>0.909152</td>\n",
       "      <td>0.595785</td>\n",
       "      <td>0.657445</td>\n",
       "      <td>0.525456</td>\n",
       "      <td>0.546300</td>\n",
       "      <td>0.486310</td>\n",
       "      <td>0.503065</td>\n",
       "      <td>0.748092</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12258</th>\n",
       "      <td>2.54</td>\n",
       "      <td>86875.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.665695</td>\n",
       "      <td>1.001047</td>\n",
       "      <td>1.001067</td>\n",
       "      <td>1.310069</td>\n",
       "      <td>0.001496</td>\n",
       "      <td>0.058674</td>\n",
       "      <td>0.130928</td>\n",
       "      <td>0.002901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.631490</td>\n",
       "      <td>0.770857</td>\n",
       "      <td>0.549534</td>\n",
       "      <td>0.628700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6040</th>\n",
       "      <td>1695.78</td>\n",
       "      <td>1007293.0</td>\n",
       "      <td>2.584918</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.206892</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.045317</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.009420</td>\n",
       "      <td>1.000644</td>\n",
       "      <td>1.000234</td>\n",
       "      <td>1.294792</td>\n",
       "      <td>0.001541</td>\n",
       "      <td>0.060918</td>\n",
       "      <td>0.081689</td>\n",
       "      <td>2.018449</td>\n",
       "      <td>1.021534</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.764171</td>\n",
       "      <td>0.747545</td>\n",
       "      <td>0.638306</td>\n",
       "      <td>0.645578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.039999</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20449 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       close_stock  volume_cash_stock  zs-20-close_stock  ma-slope-20-close_stock  std-slope-20-close_stock  rng-20_stock  percent-rng-20-close_stock  percent-std-20-close_stock  kaufmanns_efficiency_ratio-20_stock  zs-50-close_stock  ma-slope-50-close_stock  std-slope-50-close_stock  rng-50_stock  percent-rng-50-close_stock  percent-std-50-close_stock  kaufmanns_efficiency_ratio-50_stock  zs-100-close_stock  ma-slope-100-close_stock  std-slope-100-close_stock  rng-100_stock  percent-rng-100-close_stock  percent-std-100-close_stock  kaufmanns_efficiency_ratio-100_stock  zs-200-close_stock  ma-slope-200-close_stock  ...  zs-200-close_omx  ma-slope-200-close_omx  std-slope-200-close_omx  rng-200_omx  percent-rng-200-close_omx  percent-std-200-close_omx  kaufmanns_efficiency_ratio-200_omx  stock_quota  stock_hist_relative_perf20  stock_hist_relative_perf50  stock_hist_relative_perf100  stock_hist_perf20  stock_hist_perf50  stock_hist_perf100  stock_relative_rsi_3  stock_rsi_3  \\\n",
       "15988         2.03           541421.0           2.744165                 1.005824                  1.307024      1.413317                    0.696215                    0.038864                             0.203209          -0.155546                 0.992061                  0.957831      1.840452                    0.906627                    0.179947                             0.296882           -0.526132                  0.998846                   1.001157       1.840452                     0.906627                     0.165639                              0.047735           -0.985840                  0.996976  ...          0.944756                1.000610                 0.999884     1.288141                   0.000592                   0.059796                            0.066938     0.000933                    0.867213                    1.392532                     1.161365           0.896552           1.411330            1.125616              0.904683     0.943007   \n",
       "2535          2.48            53280.0           1.066610                 0.996130                  0.912574      1.473146                    0.594010                    0.061810                             0.011494          -0.440949                 0.998536                  1.001130      1.769821                    0.713637                    0.102235                             0.084112           -0.761097                  0.998364                   0.999189       1.769821                     0.713637                     0.108396                              0.003788                 NaN                       NaN  ...          0.944756                1.000610                 0.999884     1.288141                   0.000592                   0.059796                            0.066938     0.001140                    1.031363                    1.058178                     1.296622           1.072581           1.076613            1.177419              0.836680     0.826858   \n",
       "15008         3.29          1262759.0           0.880819                 0.994219                  0.882303      1.413284                    0.429570                    0.067031                             0.165899          -0.607770                 0.998938                  1.003415      1.723247                    0.523783                    0.141381                             0.064272           -0.129539                  1.003407                   0.974340       2.186047                     0.664452                     0.158734                              0.054269            0.727544                  1.001494  ...          0.944756                1.000610                 0.999884     1.288141                   0.000592                   0.059796                            0.066938     0.001513                    1.073118                    1.043662                     0.674251           1.109422           1.057751            0.653495              0.811952     0.827162   \n",
       "18774         3.95            89900.0           2.406587                 1.002250                  1.092150      1.416252                    0.358545                    0.052414                             0.167883           0.856915                 0.997569                  0.954666      1.542289                    0.390453                    0.076075                             0.070619           -0.432947                  0.998001                   0.995381       1.704809                     0.431597                     0.142123                              0.083643           -0.814556                  0.998177  ...          0.944756                1.000610                 0.999884     1.288141                   0.000592                   0.059796                            0.066938     0.001816                    0.929320                    1.099087                     1.251172           0.960759           1.113924            1.212658              0.913877     0.957879   \n",
       "102           2.37           209576.0           3.032243                 1.007771                  1.412257      1.414286                    0.596745                    0.048265                             0.228095          -0.137957                 0.994912                  0.985365      1.801143                    0.759976                    0.191278                             0.166667           -0.814632                  0.994949                   0.987717       2.285714                     0.964436                     0.231530                              0.199216           -1.100148                  0.997949  ...          0.944756                1.000610                 0.999884     1.288141                   0.000592                   0.059796                            0.066938     0.001090                    0.839939                    1.245632                     1.654299           0.868354           1.262447            1.603376              0.922219     0.949521   \n",
       "...            ...                ...                ...                      ...                       ...           ...                         ...                         ...                                  ...                ...                      ...                       ...           ...                         ...                         ...                                  ...                 ...                       ...                        ...            ...                          ...                          ...                                   ...                 ...                       ...  ...               ...                     ...                      ...          ...                        ...                        ...                                 ...          ...                         ...                         ...                          ...                ...                ...                 ...                   ...          ...   \n",
       "14056        15.00           105000.0           1.779090                 1.003655                  1.093842      1.171875                    0.078125                    0.047590                             0.036496           1.215632                 1.007848                  0.990677      2.094241                    0.139616                    0.118347                             0.073840            1.391710                  1.001604                   1.009579       2.094241                     0.139616                     0.120140                              0.024740                 NaN                       NaN  ...          1.665695                1.001047                 1.001067     1.310069                   0.001496                   0.058674                            0.130928     0.017131                    0.967337                    0.720639                     0.971465           0.933333           0.666667            0.866667              0.678072     0.755504   \n",
       "12033        80.12        128813639.0           1.977155                 1.003310                  1.105054      1.096980                    0.013692                    0.021602                             0.342804           1.739213                 1.002035                  1.031118      1.217163                    0.015192                    0.042803                             0.245393            2.342737                  1.001654                   1.019918       1.237811                     0.015449                     0.040571                              0.115607            1.600892                  0.999701  ...          1.665695                1.001047                 1.001067     1.310069                   0.001496                   0.058674                            0.130928     0.091500                    0.969966                    0.950477                     0.937717           0.936845           0.906016            0.850599              0.668307     0.902318   \n",
       "13017         3.18          2829488.0           2.042188                 1.004523                  1.136263      1.417355                    0.445709                    0.045040                             0.202614           0.819079                 1.006476                  0.917558      1.590090                    0.500028                    0.075249                             0.136364            1.400569                  1.001511                   1.010005       1.626728                     0.511550                     0.103844                              0.039501            0.360249                  0.999087  ...          1.665695                1.001047                 1.001067     1.310069                   0.001496                   0.058674                            0.130928     0.003632                    0.950702                    0.732372                     0.967483           0.918239           0.698113            0.871069              0.726121     0.909152   \n",
       "12258         2.54            86875.0                NaN                      NaN                       NaN           NaN                         NaN                         NaN                                  NaN                NaN                      NaN                       NaN           NaN                         NaN                         NaN                                  NaN                 NaN                       NaN                        NaN            NaN                          NaN                          NaN                                   NaN                 NaN                       NaN  ...          1.665695                1.001047                 1.001067     1.310069                   0.001496                   0.058674                            0.130928     0.002901                         NaN                         NaN                          NaN                NaN                NaN                 NaN              0.631490     0.770857   \n",
       "6040       1695.78          1007293.0           2.584918                 1.000000                  1.000000      1.206892                    0.000712                    0.045317                             0.083333                NaN                      NaN                       NaN           NaN                         NaN                         NaN                                  NaN                 NaN                       NaN                        NaN            NaN                          NaN                          NaN                                   NaN                 NaN                       NaN  ...          1.009420                1.000644                 1.000234     1.294792                   0.001541                   0.060918                            0.081689     2.018449                    1.021534                         NaN                          NaN           1.000000                NaN                 NaN              0.764171     0.747545   \n",
       "\n",
       "       stock_relative_rsi_10  stock_rsi_10  stock_relative_rsi_34  stock_rsi_34  stock_relative_rsi_100  stock_rsi_100    result  trades_last_year  days_since_last_signal  \n",
       "15988               0.662436      0.701801               0.483980      0.484571                0.453806       0.455930  0.034483                 1                    49.0  \n",
       "2535                0.581117      0.576352               0.478057      0.480907                0.456886       0.469512  0.016667                 1                   107.0  \n",
       "15008               0.564281      0.567580               0.496007      0.495642                0.498714       0.500740 -0.124620                 4                    40.0  \n",
       "18774               0.671920      0.698092               0.513029      0.516961                0.480894       0.485299 -0.035443                 1                    65.0  \n",
       "102                 0.672756      0.685980               0.467637      0.470723                0.424234       0.429815 -0.004158                 0                   590.0  \n",
       "...                      ...           ...                    ...           ...                     ...            ...       ...               ...                     ...  \n",
       "14056               0.555563      0.587648               0.517387      0.530934                0.475994       0.487070  0.115385                 0                     NaN  \n",
       "12033               0.581661      0.690710               0.548916      0.599993                0.479608       0.519502  1.311408                 0                     NaN  \n",
       "13017               0.595785      0.657445               0.525456      0.546300                0.486310       0.503065  0.748092                 0                     NaN  \n",
       "12258               0.549534      0.628700                    NaN           NaN                     NaN            NaN  0.377778                 0                     NaN  \n",
       "6040                0.638306      0.645578                    NaN           NaN                     NaN            NaN  0.039999                 0                     NaN  \n",
       "\n",
       "[20449 rows x 86 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "tradedf = pd.DataFrame()\n",
    "stockdf = pd.DataFrame()\n",
    "\n",
    "try: \n",
    "  df = pd.read_csv('stockytrades.csv')\n",
    "except:\n",
    "  print('Failed to read file')\n",
    "  docs = db.collection('trades').stream()\n",
    "\n",
    "  for doc in docs:\n",
    "    print('starting', doc.id)\n",
    "    stockdf = get_price_data(doc.id)\n",
    "    tradedf =  get_trade_data(doc)\n",
    "    merged_df = pd.merge(stockdf, omxdf, on='date', suffixes=('_stock', '_omx'))\n",
    "    merged_df = pd.merge(merged_df, merge_index_stock_df(omxdf, stockdf), on='date')\n",
    "\n",
    "    \n",
    "    # merged_df = pd.merge(merged_df, tradedf, on='date', suffixes=('_1', '_2'))\n",
    "    merged_df = pd.merge(merged_df, tradedf, on='date')\n",
    "    merged_df.drop(columns=['owners'], inplace = True, errors='ignore')\n",
    "    \n",
    "    df = pd.concat([df, merged_df], ignore_index=True)\n",
    "  \n",
    "  # Save the file so we dont have to next time\n",
    "  # Drop problematic columns.\n",
    "  df.to_csv('stockytrades.csv')\n",
    "\n",
    "df = df.sort_values(by=['date'], ascending=False)\n",
    "df.drop(columns=unwanted_columns, inplace=True, errors='ignore')\n",
    "\n",
    "\n",
    "print(\"have\", len(df))\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "std-slope-200-close_stock               2335\n",
       "ma-slope-200-close_stock                2334\n",
       "percent-std-200-close_stock             2324\n",
       "kaufmanns_efficiency_ratio-200_stock    2324\n",
       "rng-200_stock                           2324\n",
       "percent-rng-200-close_stock             2324\n",
       "zs-200-close_stock                      2324\n",
       "std-slope-50-volume_stock               1367\n",
       "ma-slope-50-volume_stock                1367\n",
       "percent-std-50-volume_stock             1344\n",
       "zs-50-volume_stock                      1344\n",
       "days_since_last_signal                  1288\n",
       "stock_rsi_100                           1274\n",
       "stock_relative_rsi_100                  1274\n",
       "stock_hist_perf100                      1274\n",
       "stock_hist_relative_perf100             1274\n",
       "ma-slope-100-close_stock                1272\n",
       "std-slope-100-close_stock               1272\n",
       "zs-100-close_stock                      1260\n",
       "rng-100_stock                           1260\n",
       "percent-rng-100-close_stock             1260\n",
       "percent-std-100-close_stock             1260\n",
       "kaufmanns_efficiency_ratio-100_stock    1260\n",
       "std-slope-20-volume_stock                750\n",
       "ma-slope-20-volume_stock                 749\n",
       "percent-rng-50-volume_stock              746\n",
       "stock_hist_perf50                        738\n",
       "stock_hist_relative_perf50               738\n",
       "std-slope-50-close_stock                 737\n",
       "ma-slope-50-close_stock                  737\n",
       "zs-20-volume_stock                       734\n",
       "percent-std-20-volume_stock              733\n",
       "percent-std-50-close_stock               725\n",
       "zs-50-close_stock                        725\n",
       "kaufmanns_efficiency_ratio-50_stock      725\n",
       "rng-50_stock                             725\n",
       "percent-rng-50-close_stock               725\n",
       "stock_relative_rsi_34                    543\n",
       "stock_rsi_34                             543\n",
       "percent-rng-20-volume_stock              372\n",
       "std-slope-20-close_stock                 370\n",
       "stock_hist_perf20                        362\n",
       "stock_hist_relative_perf20               362\n",
       "ma-slope-20-close_stock                  361\n",
       "zs-20-close_stock                        351\n",
       "rng-20_stock                             351\n",
       "kaufmanns_efficiency_ratio-20_stock      351\n",
       "percent-std-20-close_stock               351\n",
       "percent-rng-20-close_stock               351\n",
       "stock_rsi_10                             212\n",
       "stock_relative_rsi_10                    212\n",
       "stock_rsi_3                               80\n",
       "stock_relative_rsi_3                      80\n",
       "volume_cash_stock                         21\n",
       "result                                     0\n",
       "trades_last_year                           0\n",
       "std-slope-200-close_omx                    0\n",
       "stock_quota                                0\n",
       "kaufmanns_efficiency_ratio-200_omx         0\n",
       "percent-std-200-close_omx                  0\n",
       "percent-rng-200-close_omx                  0\n",
       "rng-200_omx                                0\n",
       "close_stock                                0\n",
       "ma-slope-200-close_omx                     0\n",
       "rng-50_omx                                 0\n",
       "zs-20-close_omx                            0\n",
       "ma-slope-20-close_omx                      0\n",
       "std-slope-20-close_omx                     0\n",
       "percent-rng-20-close_omx                   0\n",
       "percent-std-20-close_omx                   0\n",
       "kaufmanns_efficiency_ratio-20_omx          0\n",
       "zs-50-close_omx                            0\n",
       "ma-slope-50-close_omx                      0\n",
       "std-slope-50-close_omx                     0\n",
       "percent-rng-50-close_omx                   0\n",
       "zs-200-close_omx                           0\n",
       "percent-std-50-close_omx                   0\n",
       "kaufmanns_efficiency_ratio-50_omx          0\n",
       "zs-100-close_omx                           0\n",
       "ma-slope-100-close_omx                     0\n",
       "std-slope-100-close_omx                    0\n",
       "rng-100_omx                                0\n",
       "percent-rng-100-close_omx                  0\n",
       "percent-std-100-close_omx                  0\n",
       "kaufmanns_efficiency_ratio-100_omx         0\n",
       "rng-20_omx                                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trades: 17179\n"
     ]
    }
   ],
   "source": [
    "# Clean the data that cannot be used for training\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "print(\"Total number of trades:\", len(df))\n",
    "\n",
    "\n",
    "# Add the label we want to predict\n",
    "df['label'] = np.where(df['result'] > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.034287729605589005 89.56603773584905\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average 3.4287729605589004%\n",
      "Best 8956.603773584906%\n",
      "Worst -98.48192771084338%\n",
      "std 78.62588432068087%\n"
     ]
    }
   ],
   "source": [
    "#plot distribution of points by team \n",
    "avg = df['result'].mean()\n",
    "best = df['result'].max()\n",
    "worst = df['result'].min()\n",
    "std = df['result'].std()\n",
    "\n",
    "print(avg, best)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "stats = ['Average', 'Best', 'Worst', 'std']\n",
    "columns = [avg, best, worst, std]\n",
    "ax.bar(stats, columns)\n",
    "plt.show()\n",
    "\n",
    "for i in range(len(stats)):\n",
    "  print(stats[i], f'{columns[i]*100}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine learning part\n",
    "\n",
    "- Drop all `NaN` values first. \n",
    "- Then split the dataset for test and training (using K-fold?). \n",
    "- Train the model\n",
    "- Create a confusion matrix on the validation data. Compare results with reality\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # FATAL\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.getLogger('tensorflow').setLevel(logging.FATAL)\n",
    "tf.autograph.set_verbosity(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize input data\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataset\n",
    "train_data, validation_data =  train_test_split(df, test_size=0.2, shuffle=False) \n",
    "# train_data, validation_data =  train_test_split(df, test_size=0.15, random_state=42) \n",
    "\n",
    "# Split the dataset into features and target\n",
    "\n",
    "X = train_data.drop(columns=['result', 'label'], axis=1).values\n",
    "X = scaler.fit_transform(X)\n",
    "y = train_data['label'].values\n",
    "X_val = validation_data.drop(columns=['result', 'label'], axis=1).values\n",
    "X_val = scaler.transform(X_val)\n",
    "y_val = validation_data['label'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold\n",
    "num_folds = 3\n",
    "# # Define the k-fold cross-validator\n",
    "kfold = KFold(n_splits=num_folds)\n",
    "\n",
    "# print(df.columns.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define TensorFlow model\n",
    "model = tf.keras.Sequential([\n",
    "    # tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X.shape[1],)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    # tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    # tf.keras.layers.Dense(16, activation='relu'),\n",
    "    # tf.keras.layers.BatchNormalization(),\n",
    "    # tf.keras.layers.BatchNormalization(),\n",
    "    # tf.keras.layers.Dropout(0.5),\n",
    "    # tf.keras.layers.Dense(32, activation='relu'),\n",
    "    # tf.keras.layers.BatchNormalization(),\n",
    "    # tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0003)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'], )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bauhn\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0 1], y=[1 0 0 ... 0 0 0] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=17, restore_best_weights=False)\n",
    "\n",
    "# Define learning rate scheduler callback\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.5)\n",
    "\n",
    "\n",
    "\n",
    "# Calculate class weights based on occurrence since the base strategy loses more often we want to equalize the weights\n",
    "class_weights = compute_class_weight('balanced', np.unique(y), y)\n",
    "\n",
    "# Convert class weights to a dictionary\n",
    "class_weights_dict = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "859/859 [==============================] - 2s 2ms/step - loss: 0.8447 - accuracy: 0.5030 - val_loss: 0.7395 - val_accuracy: 0.5338 - lr: 3.0000e-04\n",
      "Epoch 2/200\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.7368 - accuracy: 0.5353 - val_loss: 0.7070 - val_accuracy: 0.5419 - lr: 3.0000e-04\n",
      "Epoch 3/200\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.7086 - accuracy: 0.5548 - val_loss: 0.7127 - val_accuracy: 0.5431 - lr: 3.0000e-04\n",
      "Epoch 4/200\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.6958 - accuracy: 0.5595 - val_loss: 0.7161 - val_accuracy: 0.5338 - lr: 3.0000e-04\n",
      "Epoch 5/200\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5712 - val_loss: 0.7096 - val_accuracy: 0.5387 - lr: 3.0000e-04\n",
      "Epoch 6/200\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.6826 - accuracy: 0.5752 - val_loss: 0.7209 - val_accuracy: 0.5381 - lr: 3.0000e-04\n",
      "Epoch 7/200\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.6758 - accuracy: 0.5899 - val_loss: 0.7219 - val_accuracy: 0.5274 - lr: 3.0000e-04\n",
      "Epoch 8/200\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.6729 - accuracy: 0.5930 - val_loss: 0.7197 - val_accuracy: 0.5335 - lr: 1.5000e-04\n",
      "Epoch 9/200\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.6694 - accuracy: 0.6029 - val_loss: 0.7213 - val_accuracy: 0.5212 - lr: 1.5000e-04\n",
      "Epoch 10/200\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.6708 - accuracy: 0.6004 - val_loss: 0.7243 - val_accuracy: 0.5332 - lr: 1.5000e-04\n",
      "Epoch 11/200\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.6699 - accuracy: 0.6075 - val_loss: 0.7198 - val_accuracy: 0.5375 - lr: 1.5000e-04\n",
      "Epoch 12/200\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.6685 - accuracy: 0.6075 - val_loss: 0.7245 - val_accuracy: 0.5358 - lr: 1.5000e-04\n",
      "Epoch 13/200\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.6664 - accuracy: 0.6096 - val_loss: 0.7259 - val_accuracy: 0.5445 - lr: 7.5000e-05\n",
      "Epoch 14/200\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.6647 - accuracy: 0.6135 - val_loss: 0.7305 - val_accuracy: 0.5434 - lr: 7.5000e-05\n",
      "Epoch 15/200\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.6625 - accuracy: 0.6170 - val_loss: 0.7222 - val_accuracy: 0.5477 - lr: 7.5000e-05\n",
      "Epoch 16/200\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.6642 - accuracy: 0.6157 - val_loss: 0.7369 - val_accuracy: 0.5341 - lr: 7.5000e-05\n",
      "Epoch 17/200\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.6614 - accuracy: 0.6191 - val_loss: 0.7358 - val_accuracy: 0.5338 - lr: 7.5000e-05\n",
      "Epoch 18/200\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.6628 - accuracy: 0.6170 - val_loss: 0.7172 - val_accuracy: 0.5454 - lr: 3.7500e-05\n",
      "Epoch 19/200\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.6636 - accuracy: 0.6152 - val_loss: 0.7234 - val_accuracy: 0.5469 - lr: 3.7500e-05\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "# Train the model using k-fold cross-validation\n",
    "# for train_index, val_index in kfold.split(X):\n",
    "#     X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
    "#     y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "\n",
    "#     # Scale the data\n",
    "#     X_train_fold_scaled = scaler.fit_transform(X_train_fold)\n",
    "#     X_val_fold_scaled = scaler.transform(X_val_fold)\n",
    "\n",
    "\n",
    "#     # Train the model\n",
    "#     model.fit(X_train_fold_scaled, \n",
    "#               y_train_fold, \n",
    "#               epochs=50, \n",
    "#               batch_size=32, \n",
    "#               validation_data=(X_val_fold_scaled, y_val_fold), \n",
    "#               callbacks=[lr_scheduler, early_stopping],  \n",
    "#               class_weight=class_weights_dict \n",
    "#             )\n",
    "#     print(\"hello\")\n",
    "# Train the model using k-fold cross-validation\n",
    "\n",
    "    # Train the model\n",
    "model.fit(X, y, \n",
    "              epochs=200, \n",
    "              batch_size=16, \n",
    "              validation_data=(X_val, y_val), \n",
    "              callbacks=[lr_scheduler, early_stopping],  \n",
    "            #   callbacks=[ early_stopping],  \n",
    "              class_weight=class_weights_dict \n",
    "            )\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "# Skippa K-means och se till att uppdatera scalern på hela träningssetet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scale the validation data with the same scaler used for the training data\n",
    "validation_x = scaler.transform(validation_data.drop(columns=['result', 'label'], axis=1).values)\n",
    "\n",
    "# Run predictions on the validation dataset\n",
    "y_pred = model.predict(validation_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49372825]] 12876   -0.090323\n",
      "Name: result, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "item = validation_data.sample(1)\n",
    "x = scaler.transform(item.drop(columns=['result', 'label'], axis=1).values)\n",
    "\n",
    "print(model.predict([x]), item[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0649353 , -0.22281929,  0.80026716,  0.21545421, -0.19920815,\n",
       "        -0.16561482, -0.16494886, -0.12412815,  0.58380019,  0.07024958,\n",
       "         0.33500504, -0.10978527, -0.01485749, -0.01474518, -0.09922974,\n",
       "         0.08733902,  0.23857558,  0.08577721, -0.02171217, -0.01495729,\n",
       "        -0.01477781, -0.0332937 , -1.09725724, -0.5829345 , -0.50092192,\n",
       "        -0.12652835, -0.01591547, -0.01488866, -0.02603431,  0.05735982,\n",
       "        -0.768233  , -0.31699818, -0.23417384, -0.01657717, -0.03121327,\n",
       "        -0.81516533, -0.15935292, -0.15749567, -0.0184057 , -0.03014699,\n",
       "         0.8003564 ,  0.65958336,  0.59010642,  1.43655268,  5.0990891 ,\n",
       "         0.17276732, -0.74948469,  0.25975651,  2.60076796, -0.25377548,\n",
       "         3.77622089,  6.10789915,  3.80688683,  0.64082525,  0.7242388 ,\n",
       "         1.25081009,  1.12078392,  2.08034648,  6.16029166,  2.55059911,\n",
       "        -0.35822145, -0.16650376, -2.49962329, -1.30425113,  2.79698662,\n",
       "         7.25038034,  3.0009241 , -0.75032244, -0.05197461, -0.13678451,\n",
       "        -0.10771794, -0.02059075, -0.15455904, -0.21964801, -0.03726705,\n",
       "         0.97033619,  0.96260597,  0.07345173,  0.38364318, -0.27192162,\n",
       "         0.18453855, -0.37987003, -0.46370134, -0.56319895, -0.53638976]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wtf = item.drop(columns=[\"result\", \"label\"], axis=1).values\n",
    "\n",
    "\n",
    "\n",
    "scaler.transform(wtf)\n",
    "# wtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in validation_data.sample(10).drop(columns=['result', 'label'], axis=1).values:\n",
    "    # print().shape)\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.5468568102444703 - precision: 0.47585601404741 - recall: 0.7491361437456807 - f1 0.582013422818792\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(validation_data['label'], np.where(y_pred > 0.5, 1, 0).flatten()).ravel()\n",
    "\n",
    "accuracy = (tp+tn) / (tp+tn+fn+fp)\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f1 = 2 * (precision*recall)/(precision+recall)\n",
    "\n",
    "print(f'accuracy: {accuracy} - precision: {precision} - recall: {recall} - f1 {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(df, name):\n",
    "    winners = df[df['result'] >= 0]\n",
    "    losers = df[df['result'] < 0]\n",
    "    \n",
    "    return pd.DataFrame.from_dict({\n",
    "        'count': len(df),\n",
    "        'avg': df['result'].mean(),\n",
    "        'winrate': len(winners) / len(df),\n",
    "        'avg_winner': winners['result'].mean(),\n",
    "        'avg_loser': losers['result'].mean(),\n",
    "        'gain_loss_ratio': winners['result'].mean() /-losers['result'].mean(),\n",
    "        'total_win': winners['result'].sum(),\n",
    "        'total_loss':  losers['result'].sum(),\n",
    "        'profit_factor': winners['result'].sum() / -losers['result'].sum()\n",
    "    }, orient='index', columns=[name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "      <th>validation dataset</th>\n",
       "      <th>predicted winners</th>\n",
       "      <th>predicted losers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17179.000000</td>\n",
       "      <td>3436.000000</td>\n",
       "      <td>2278.000000</td>\n",
       "      <td>1158.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg</th>\n",
       "      <td>0.034288</td>\n",
       "      <td>0.085841</td>\n",
       "      <td>0.114447</td>\n",
       "      <td>0.029567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winrate</th>\n",
       "      <td>0.374061</td>\n",
       "      <td>0.452270</td>\n",
       "      <td>0.496488</td>\n",
       "      <td>0.365285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_winner</th>\n",
       "      <td>0.310639</td>\n",
       "      <td>0.340644</td>\n",
       "      <td>0.347297</td>\n",
       "      <td>0.322857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_loser</th>\n",
       "      <td>-0.130860</td>\n",
       "      <td>-0.124555</td>\n",
       "      <td>-0.115155</td>\n",
       "      <td>-0.139224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gain_loss_ratio</th>\n",
       "      <td>2.373828</td>\n",
       "      <td>2.734896</td>\n",
       "      <td>3.015917</td>\n",
       "      <td>2.318974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_win</th>\n",
       "      <td>1996.165063</td>\n",
       "      <td>529.361046</td>\n",
       "      <td>392.792558</td>\n",
       "      <td>136.568488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_loss</th>\n",
       "      <td>-1407.136156</td>\n",
       "      <td>-234.411978</td>\n",
       "      <td>-132.082311</td>\n",
       "      <td>-102.329667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>profit_factor</th>\n",
       "      <td>1.418601</td>\n",
       "      <td>2.258251</td>\n",
       "      <td>2.973847</td>\n",
       "      <td>1.334593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          all  validation dataset  predicted winners  predicted losers\n",
       "count            17179.000000         3436.000000        2278.000000       1158.000000\n",
       "avg                  0.034288            0.085841           0.114447          0.029567\n",
       "winrate              0.374061            0.452270           0.496488          0.365285\n",
       "avg_winner           0.310639            0.340644           0.347297          0.322857\n",
       "avg_loser           -0.130860           -0.124555          -0.115155         -0.139224\n",
       "gain_loss_ratio      2.373828            2.734896           3.015917          2.318974\n",
       "total_win         1996.165063          529.361046         392.792558        136.568488\n",
       "total_loss       -1407.136156         -234.411978        -132.082311       -102.329667\n",
       "profit_factor        1.418601            2.258251           2.973847          1.334593"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = validation_data[['result', 'label']].copy()\n",
    "res['pred'] = y_pred\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "all_trades = summarize(df, \"all\")\n",
    "val_trades = summarize(res, \"validation dataset\")\n",
    "pred_winners = summarize(res[res['pred'] > threshold], \"predicted winners\")\n",
    "pred_losers = summarize(res[res['pred'] <= threshold], \"predicted losers\")\n",
    "\n",
    "\n",
    "pd.concat([all_trades, val_trades, pred_winners, pred_losers,], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3456 - Benchmark innan Kaufman + trade count features\n",
    "```csv\n",
    "stat,all,predicted winners,predicted losers\n",
    "count,2621.000000,1036.000000,1585.000000\n",
    "avg,0.029182,0.112754,-0.025443\n",
    "winrate,0.375048,0.519305,0.280757\n",
    "avg_winner,0.296503,0.317832,0.270716\n",
    "avg_loser,-0.131243,-0.108796,-0.141048\n",
    "total_win,291.461980,170.993371,120.468609\n",
    "total_loss,-214.975741,-54.180457,-160.795284\n",
    "profit_factor,1.355790,3.155997,0.749205\n",
    "```\n",
    "#### 3456 - Benchmark innan Kaufman + efter trade count features\n",
    "```csv\n",
    "\n",
    "stat,all,predicted winners,predicted losers\n",
    "count,2569.000000,970.000000,1599.000000\n",
    "avg,0.033677,0.120749,-0.019144\n",
    "winrate,0.384196,0.512371,0.306442\n",
    "avg_winner,0.295127,0.342731,0.246843\n",
    "avg_loser,-0.129441,-0.112497,-0.136667\n",
    "total_win,291.290120,170.337085,120.953035\n",
    "total_loss,-204.774914,-53.210891,-151.564022\n",
    "profit_factor,1.422489,3.201170,0.798033\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter( res['pred'], res['result'] +1)\n",
    "ax.set_yscale(\"log\");\n",
    "# ax.set_xscale(\"log\");\n",
    "# All above 1 is winners\n",
    "plt.axhline(y=1, color='r', linestyle='-')\n",
    "# All above threshold is predicted to be winners\n",
    "plt.axvline(x=threshold, color='r', linestyle='-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0: 25', '10: 4', '20: 9', '30: 12', '40: 1108', '50: 1774', '60: 397', '70: 89', '80: 13', '90: 5']\n",
      "[3.3615890892224383, 0.5895575886516089, 7.8701369566129715, 1.987827487773526, 1.2543188875088718, 3.552815920518793, 1.4698361711074237, 0.6612460716031525, 0.22125264788149301, 5.053256635428942]\n"
     ]
    }
   ],
   "source": [
    "def divide(a, b):\n",
    "    return b and a / b or 0\n",
    "\n",
    "def getStats(inrange):\n",
    "    winners = inrange[inrange['result'] >= 0]\n",
    "    losers = inrange[inrange['result'] <= 0]\n",
    "        \n",
    "    d = {\n",
    "        'winrate': divide(len(winners),len(inrange)),\n",
    "        'profit_factor': divide(winners['result'].sum(), -losers['result'].sum())\n",
    "    }\n",
    "    return d\n",
    "\n",
    "percentiles = []\n",
    "percentiles_print = []\n",
    "winrates_above = []\n",
    "profitfactors_above = []\n",
    "winrates_below = []\n",
    "profitfactors_below = []\n",
    "\n",
    "for i in range(10):\n",
    "    in_range =res[res['pred'].between(i/10, (i+1)/10)]\n",
    "    percentiles.append(i*10)\n",
    "    percentiles_print.append(f'{i*10}: {len(in_range)}')\n",
    "\n",
    "    # Probability Above i/10\n",
    "    above = getStats(in_range)\n",
    "    winrates_above.append(above['winrate'])\n",
    "    profitfactors_above.append(above['profit_factor'])\n",
    "\n",
    "    # Probability below i/10\n",
    "    below = getStats(res[res['pred'] < i/10])\n",
    "    winrates_below.append(below['winrate'])\n",
    "    profitfactors_below.append(below['profit_factor'])\n",
    "\n",
    "print(percentiles_print)\n",
    "print(profitfactors_above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax1.bar( percentiles, winrates_above)\n",
    "plt.axhline(y=0.5, color='r', linestyle=':')\n",
    "plt.xlabel('Predicted Probability Above')\n",
    "fig2, ax2 = plt.subplots()\n",
    "ax2.bar( percentiles, winrates_below)\n",
    "plt.axhline(y=0.5, color='r', linestyle=':')\n",
    "plt.xlabel('Predicted Probability Below')\n",
    "plt.ylabel('Winrate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.bar( percentiles, profitfactors_above)\n",
    "plt.axhline(y=1, color='r', linestyle=':')\n",
    "plt.xlabel('Predicted Probability above')\n",
    "plt.ylabel('Profit factor')\n",
    "\n",
    "fig, ax2 = plt.subplots()\n",
    "ax2.bar( percentiles, profitfactors_below)\n",
    "plt.axhline(y=1, color='r', linestyle=':')\n",
    "plt.xlabel('Predicted Probability below')\n",
    "plt.ylabel('Profit factor')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the scaler to a file using joblib.dump\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "#scaler = joblib.load(\"scaler.joblib\")\n",
    "\n",
    "# Save the model to a file using model.save\n",
    "model.save(\"out/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import List, Dict\n",
    "\n",
    "# import requests\n",
    "# import pandas as pd\n",
    "\n",
    "def convert_price_data_to_dataframe(json_data):\n",
    "    # parse the JSON data into a list of dictionaries\n",
    "    data = json.loads(json_data)\n",
    "    \n",
    "    # create a pandas DataFrame from the list of dictionaries\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # convert the \"Date\" column to datetime format\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# make an API call to retrieve the price data\n",
    "# url = \"http://example.com/api/price_data\"\n",
    "# response = requests.get(url)\n",
    "\n",
    "# # pass the response content to the function\n",
    "# df = convert_price_data_to_dataframe(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6688f5bd7a5c2379fdfde91b010ab5a3ba8033d4f740240b607cd397292295b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
